{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAY_38(7-7-2020).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_BfIbYuuu55",
        "colab_type": "text"
      },
      "source": [
        "# Class(day-38:7-7-20)\n",
        "## Document link:- https://docs.google.com/document/d/1FlNFwN57ySHI1hvq_21ZX0qYDOdQpmEhxPSnYMQUI1c/edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWqfyD3GmCfK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a48bc5dd-b70e-4e6c-ad3e-b3b6001e995d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJDrGKGlmCpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9fc8846a-b7ca-4ed8-d29a-86f43ffada77"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/sumathi16/Datasets/master/titanic.csv\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNCc5eBYmCv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "7bd78a23-3681-4e86-a431-11c2bfe2bc4f"
      },
      "source": [
        "# Creating a new column Family in the dataset  by adding SibSp column and Parch column\n",
        "df['Family'] = df['SibSp'] + df['Parch']\n",
        "df.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ... Cabin Embarked  Family\n",
              "0            1         0       3  ...   NaN        S       1\n",
              "1            2         1       1  ...   C85        C       1\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj5mztg7mCzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ticket--> As it is just a random number, we can skip this column from our analysis\n",
        "df.drop('Ticket',axis=1,inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt3_L48wu_Fa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "86fbfb37-e055-4b8e-d9ca-d96008a45173"
      },
      "source": [
        "## Imputing with missing values\n",
        "df.isnull().mean().sort_values(ascending=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cabin          0.771044\n",
              "Age            0.198653\n",
              "Embarked       0.002245\n",
              "Family         0.000000\n",
              "Fare           0.000000\n",
              "Parch          0.000000\n",
              "SibSp          0.000000\n",
              "Gender         0.000000\n",
              "Name           0.000000\n",
              "Pclass         0.000000\n",
              "Survived       0.000000\n",
              "PassengerId    0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9JBm6nNvB-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing Cabin column because 77% are missing value\n",
        "df.drop('Cabin',axis=1,inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1wVj11jvE3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddfb8bf9-10f1-4093-cbc8-6adb9f239694"
      },
      "source": [
        "# Median---> sorting in the order (middle value) NaN in the age column should be substituted with median of age\n",
        "df.Age.fillna(df.Age.median(), inplace=True)\n",
        "df.Age.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF6wkSwvvHX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bdce847-9298-427e-b107-5607023754ee"
      },
      "source": [
        "## Imputing the Embarked Column---> Mode Imputation\n",
        "df.Embarked.fillna(df.Embarked.mode()[0], inplace=True)\n",
        "df.Embarked.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXwLpDc_vLCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cc62e84b-e51b-409c-d898-b1d6454e9e94"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Survived       0\n",
              "Pclass         0\n",
              "Name           0\n",
              "Gender         0\n",
              "Age            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Fare           0\n",
              "Embarked       0\n",
              "Family         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdDBeq4yvNXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "649979c9-afb1-44ac-b326-63d978076e8f"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      int64\n",
              "Survived         int64\n",
              "Pclass           int64\n",
              "Name            object\n",
              "Gender          object\n",
              "Age            float64\n",
              "SibSp            int64\n",
              "Parch            int64\n",
              "Fare           float64\n",
              "Embarked        object\n",
              "Family           int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wgbpHBjvPt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Remove passenger ID\n",
        "df.drop('PassengerId',axis=1,inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2M-pjMkvSFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop('Name',axis=1,inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBFbp74xvYYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "13d0fdc7-524f-4e3e-ee4b-8d8412ceb403"
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived      2\n",
              "Pclass        3\n",
              "Gender        2\n",
              "Age          88\n",
              "SibSp         7\n",
              "Parch         7\n",
              "Fare        248\n",
              "Embarked      3\n",
              "Family        9\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFJB1sPevbDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8292807e-0c9f-4e0a-dd78-33659f8a34b4"
      },
      "source": [
        "## Seperating the Input and Output Data, dropping the Survived column from the data\n",
        "X = df.drop('Survived', axis=1)\n",
        "X.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD35l5kzvdTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ddc86a7-33a7-4639-ee12-82a140892314"
      },
      "source": [
        "X= pd.get_dummies(X)\n",
        "X.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dwAqWEkvfff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c216d602-a9a7-4c55-b865-9a36665cd644"
      },
      "source": [
        "## Output Column\n",
        "y = df.iloc[:,0]\n",
        "y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNEa5Amjvh9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23) \n",
        "                                                        # random_state = to select the constant rows"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYGCKxRvvlUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "891d312b-d8a9-4fef-cb92-c12885226ecb"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(668, 11)\n",
            "(223, 11)\n",
            "(668,)\n",
            "(223,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSX_omAgvnie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b2750c35-b763-448c-f754-72391659df00"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression() # creating an object for Logistic Regression\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_train_pred = log_reg.predict(X_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4oSrNU7vqJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bba1863-5e98-4b32-c233-729ccde5420e"
      },
      "source": [
        "## accuracy_score---> With help of this metric, we can evaluate the overall \n",
        "## performance of the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train, y_train_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8098802395209581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHamB7cEvsaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the package\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "# Instance creation\n",
        "adc = AdaBoostClassifier()\n",
        "# Train the model\n",
        "adc.fit(X_train,y_train)\n",
        "# prediction\n",
        "y_pred = adc.predict(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptft_id_vvF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c62c5257-c069-4627-bb9d-cadf7a8640ac"
      },
      "source": [
        "accuracy_score(y_pred, y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8071748878923767"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3BAtKpBvxtm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6201175-adfa-4382-ee55-879bcef36076"
      },
      "source": [
        "accuracy_score(y_train,adc.predict(X_train) )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8413173652694611"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcDNrlDpv0U0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "71227a4a-cf82-48f3-8e95-b5ddcf198188"
      },
      "source": [
        "adc"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=50, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkfjehmFv2sU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "619c07e4-74df-442a-e764-b74b3a8525ce"
      },
      "source": [
        "# Importing the package\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "# Instance creation\n",
        "adc = AdaBoostClassifier(learning_rate = 1,n_estimators = 75)\n",
        "# Train the model\n",
        "adc.fit(X_train,y_train)\n",
        "# prediction\n",
        "y_pred = adc.predict(X_test)\n",
        "print(\"test accuarcy\",accuracy_score(y_pred, y_test))\n",
        "print(\"train accuarcy\",accuracy_score(y_train,adc.predict(X_train) ))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuarcy 0.7982062780269058\n",
            "train accuarcy 0.8398203592814372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGmbLg9Zv_bY",
        "colab_type": "text"
      },
      "source": [
        "## With base learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Ul9tUJwAWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0361cad0-88dc-4945-ce8a-059dbb8b5697"
      },
      "source": [
        "# Importing the package\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Instance creation with base estimator\n",
        "adc = AdaBoostClassifier(base_estimator= LogisticRegression())\n",
        "# Train the model\n",
        "adc.fit(X_train,y_train)\n",
        "# prediction\n",
        "y_pred = adc.predict(X_test)\n",
        "print(\"test accuarcy\",accuracy_score(y_pred, y_test))\n",
        "print(\"train accuarcy\",accuracy_score(y_train,adc.predict(X_train) ))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuarcy 0.7623318385650224\n",
            "train accuarcy 0.8068862275449101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0FSvlu-wDhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a058b7db-4101-4f1e-feca-a73e4ac70d90"
      },
      "source": [
        "# import the algo\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gdc = GradientBoostingClassifier()\n",
        "gdc.fit(X_train,y_train)\n",
        "# prediction\n",
        "y_pred = gdc.predict(X_test)\n",
        "print(\"test accuarcy\",accuracy_score(y_pred, y_test))\n",
        "print(\"train accuarcy\",accuracy_score(y_train,gdc.predict(X_train) ))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuarcy 0.8071748878923767\n",
            "train accuarcy 0.905688622754491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oko6372TwLEd",
        "colab_type": "text"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2G5a5vfwMNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train,y_train)\n",
        "# make prediction\n",
        "preds = xgb.predict(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlqTIXHywP-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ce59a472-dec1-4ef6-ad73-f16a4ab77608"
      },
      "source": [
        "xgb"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5tG_FzlwXnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a4ed4e6-68f1-48a9-b485-2de69da6125c"
      },
      "source": [
        "### Check the documentation\n",
        "help(xgb)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on XGBClassifier in module xgboost.sklearn object:\n",
            "\n",
            "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
            " |  Implementation of the scikit-learn API for XGBoost classification.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  max_depth : int\n",
            " |      Maximum tree depth for base learners.\n",
            " |  learning_rate : float\n",
            " |      Boosting learning rate (xgb's \"eta\")\n",
            " |  n_estimators : int\n",
            " |      Number of trees to fit.\n",
            " |  verbosity : int\n",
            " |      The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
            " |  silent : boolean\n",
            " |      Whether to print messages while running boosting. Deprecated. Use verbosity instead.\n",
            " |  objective : string or callable\n",
            " |      Specify the learning task and the corresponding learning objective or\n",
            " |      a custom objective function to be used (see note below).\n",
            " |  booster: string\n",
            " |      Specify which booster to use: gbtree, gblinear or dart.\n",
            " |  nthread : int\n",
            " |      Number of parallel threads used to run xgboost.  (Deprecated, please use ``n_jobs``)\n",
            " |  n_jobs : int\n",
            " |      Number of parallel threads used to run xgboost.  (replaces ``nthread``)\n",
            " |  gamma : float\n",
            " |      Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            " |  min_child_weight : int\n",
            " |      Minimum sum of instance weight(hessian) needed in a child.\n",
            " |  max_delta_step : int\n",
            " |      Maximum delta step we allow each tree's weight estimation to be.\n",
            " |  subsample : float\n",
            " |      Subsample ratio of the training instance.\n",
            " |  colsample_bytree : float\n",
            " |      Subsample ratio of columns when constructing each tree.\n",
            " |  colsample_bylevel : float\n",
            " |      Subsample ratio of columns for each level.\n",
            " |  colsample_bynode : float\n",
            " |      Subsample ratio of columns for each split.\n",
            " |  reg_alpha : float (xgb's alpha)\n",
            " |      L1 regularization term on weights\n",
            " |  reg_lambda : float (xgb's lambda)\n",
            " |      L2 regularization term on weights\n",
            " |  scale_pos_weight : float\n",
            " |      Balancing of positive and negative weights.\n",
            " |  base_score:\n",
            " |      The initial prediction score of all instances, global bias.\n",
            " |  seed : int\n",
            " |      Random number seed.  (Deprecated, please use random_state)\n",
            " |  random_state : int\n",
            " |      Random number seed.  (replaces seed)\n",
            " |  missing : float, optional\n",
            " |      Value in the data which needs to be present as a missing value. If\n",
            " |      None, defaults to np.nan.\n",
            " |  importance_type: string, default \"gain\"\n",
            " |      The feature importance type for the feature_importances_ property: either \"gain\",\n",
            " |      \"weight\", \"cover\", \"total_gain\" or \"total_cover\".\n",
            " |  \\*\\*kwargs : dict, optional\n",
            " |      Keyword arguments for XGBoost Booster object.  Full documentation of parameters can\n",
            " |      be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
            " |      Attempting to set a parameter via the constructor args and \\*\\*kwargs dict simultaneously\n",
            " |      will result in a TypeError.\n",
            " |  \n",
            " |      .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
            " |  \n",
            " |          \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee that parameters\n",
            " |          passed via this argument will interact properly with scikit-learn.\n",
            " |  \n",
            " |  Note\n",
            " |  ----\n",
            " |  A custom objective function can be provided for the ``objective``\n",
            " |  parameter. In this case, it should have the signature\n",
            " |  ``objective(y_true, y_pred) -> grad, hess``:\n",
            " |  \n",
            " |  y_true: array_like of shape [n_samples]\n",
            " |      The target values\n",
            " |  y_pred: array_like of shape [n_samples]\n",
            " |      The predicted values\n",
            " |  \n",
            " |  grad: array_like of shape [n_samples]\n",
            " |      The value of the gradient for each sample point.\n",
            " |  hess: array_like of shape [n_samples]\n",
            " |      The value of the second derivative for each sample point\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      XGBClassifier\n",
            " |      XGBModel\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  evals_result(self)\n",
            " |      Return the evaluation results.\n",
            " |      \n",
            " |      If **eval_set** is passed to the `fit` function, you can call\n",
            " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.\n",
            " |      When **eval_metric** is also passed to the `fit` function, the\n",
            " |      **evals_result** will contain the **eval_metrics** passed to the `fit` function.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      evals_result : dictionary\n",
            " |      \n",
            " |      Example\n",
            " |      -------\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          param_dist = {'objective':'binary:logistic', 'n_estimators':2}\n",
            " |      \n",
            " |          clf = xgb.XGBClassifier(**param_dist)\n",
            " |      \n",
            " |          clf.fit(X_train, y_train,\n",
            " |                  eval_set=[(X_train, y_train), (X_test, y_test)],\n",
            " |                  eval_metric='logloss',\n",
            " |                  verbose=True)\n",
            " |      \n",
            " |          evals_result = clf.evals_result()\n",
            " |      \n",
            " |      The variable **evals_result** will contain\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
            " |          'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n",
            " |      Fit gradient boosting classifier\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array_like\n",
            " |          Feature matrix\n",
            " |      y : array_like\n",
            " |          Labels\n",
            " |      sample_weight : array_like\n",
            " |          Weight for each instance\n",
            " |      eval_set : list, optional\n",
            " |          A list of (X, y) pairs to use as a validation set for\n",
            " |          early-stopping\n",
            " |      sample_weight_eval_set : list, optional\n",
            " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n",
            " |          instance weights on the i-th validation set.\n",
            " |      eval_metric : str, callable, optional\n",
            " |          If a str, should be a built-in evaluation metric to use. See\n",
            " |          doc/parameter.rst. If callable, a custom evaluation metric. The call\n",
            " |          signature is func(y_predicted, y_true) where y_true will be a\n",
            " |          DMatrix object such that you may need to call the get_label\n",
            " |          method. It must return a str, value pair where the str is a name\n",
            " |          for the evaluation and value is the value of the evaluation\n",
            " |          function. This objective is always minimized.\n",
            " |      early_stopping_rounds : int, optional\n",
            " |          Activates early stopping. Validation error needs to decrease at\n",
            " |          least every <early_stopping_rounds> round(s) to continue training.\n",
            " |          Requires at least one item in evals. If there's more than one,\n",
            " |          will use the last. If early stopping occurs, the model will have\n",
            " |          three additional fields: bst.best_score, bst.best_iteration and\n",
            " |          bst.best_ntree_limit (bst.best_ntree_limit is the ntree_limit parameter\n",
            " |          default value in predict method if not any other value is specified).\n",
            " |          (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n",
            " |          and/or num_class appears in the parameters)\n",
            " |      verbose : bool\n",
            " |          If `verbose` and an evaluation set is used, writes the evaluation\n",
            " |          metric measured on the validation set to stderr.\n",
            " |      xgb_model : str\n",
            " |          file name of stored xgb model or 'Booster' instance Xgb model to be\n",
            " |          loaded before training (allows training continuation).\n",
            " |      callbacks : list of callback functions\n",
            " |          List of callback functions that are applied at end of each iteration.\n",
            " |          It is possible to use predefined callbacks by using :ref:`callback_api`.\n",
            " |          Example:\n",
            " |      \n",
            " |          .. code-block:: python\n",
            " |      \n",
            " |              [xgb.callback.reset_learning_rate(custom_rates)]\n",
            " |  \n",
            " |  predict(self, data, output_margin=False, ntree_limit=None, validate_features=True)\n",
            " |      Predict with `data`.\n",
            " |      \n",
            " |      .. note:: This function is not thread safe.\n",
            " |      \n",
            " |        For each booster object, predict can only be called from one thread.\n",
            " |        If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
            " |        of model object and then call ``predict()``.\n",
            " |      \n",
            " |      .. note:: Using ``predict()`` with DART booster\n",
            " |      \n",
            " |        If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only\n",
            " |        some of the trees will be evaluated. This will produce incorrect results if ``data`` is\n",
            " |        not the training data. To obtain correct results on test sets, set ``ntree_limit`` to\n",
            " |        a nonzero value, e.g.\n",
            " |      \n",
            " |        .. code-block:: python\n",
            " |      \n",
            " |          preds = bst.predict(dtest, ntree_limit=num_round)\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      data : DMatrix\n",
            " |          The dmatrix storing the input.\n",
            " |      output_margin : bool\n",
            " |          Whether to output the raw untransformed margin value.\n",
            " |      ntree_limit : int\n",
            " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
            " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
            " |      validate_features : bool\n",
            " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
            " |          Otherwise, it is assumed that the feature_names are the same.\n",
            " |      Returns\n",
            " |      -------\n",
            " |      prediction : numpy array\n",
            " |  \n",
            " |  predict_proba(self, data, ntree_limit=None, validate_features=True)\n",
            " |      Predict the probability of each `data` example being of a given class.\n",
            " |      \n",
            " |      .. note:: This function is not thread safe\n",
            " |      \n",
            " |          For each booster object, predict can only be called from one thread.\n",
            " |          If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
            " |          of model object and then call predict\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      data : DMatrix\n",
            " |          The dmatrix storing the input.\n",
            " |      ntree_limit : int\n",
            " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
            " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
            " |      validate_features : bool\n",
            " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
            " |          Otherwise, it is assumed that the feature_names are the same.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      prediction : numpy array\n",
            " |          a numpy array with the probability of each data example being of a given class.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from XGBModel:\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  apply(self, X, ntree_limit=0)\n",
            " |      Return the predicted leaf every tree for each sample.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array_like, shape=[n_samples, n_features]\n",
            " |          Input features matrix.\n",
            " |      \n",
            " |      ntree_limit : int\n",
            " |          Limit number of trees in the prediction; defaults to 0 (use all trees).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
            " |          For each datapoint x in X and for each tree, return the index of the\n",
            " |          leaf x ends up in. Leaves are numbered within\n",
            " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
            " |  \n",
            " |  get_booster(self)\n",
            " |      Get the underlying xgboost Booster of this model.\n",
            " |      \n",
            " |      This will raise an exception when fit was not called\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      booster : a xgboost booster of underlying model\n",
            " |  \n",
            " |  get_num_boosting_rounds(self)\n",
            " |      Gets the number of xgboost boosting rounds.\n",
            " |  \n",
            " |  get_params(self, deep=False)\n",
            " |      Get parameters.\n",
            " |  \n",
            " |  get_xgb_params(self)\n",
            " |      Get xgboost type parameters.\n",
            " |  \n",
            " |  load_model(self, fname)\n",
            " |      Load the model from a file.\n",
            " |      \n",
            " |      The model is loaded from an XGBoost internal binary format which is\n",
            " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
            " |      the Python Booster object (such as feature names) will not be loaded.\n",
            " |      Label encodings (text labels to numeric labels) will be also lost.\n",
            " |      **If you are using only the Python interface, we recommend pickling the\n",
            " |      model object for best results.**\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      fname : string or a memory buffer\n",
            " |          Input file name or memory buffer(see also save_raw)\n",
            " |  \n",
            " |  save_model(self, fname)\n",
            " |      Save the model to a file.\n",
            " |      \n",
            " |      The model is saved in an XGBoost internal binary format which is\n",
            " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
            " |      the Python Booster object (such as feature names) will not be loaded.\n",
            " |      Label encodings (text labels to numeric labels) will be also lost.\n",
            " |      **If you are using only the Python interface, we recommend pickling the\n",
            " |      model object for best results.**\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      fname : string\n",
            " |          Output file name\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      Modification of the sklearn method to allow unknown kwargs. This allows using\n",
            " |      the full range of xgboost parameters that are not defined as member variables\n",
            " |      in sklearn grid search.\n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from XGBModel:\n",
            " |  \n",
            " |  coef_\n",
            " |      Coefficients property\n",
            " |      \n",
            " |      .. note:: Coefficients are defined only for linear learners\n",
            " |      \n",
            " |          Coefficients are only defined when the linear model is chosen as base\n",
            " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
            " |          as tree learners (`booster=gbtree`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      Feature importances property\n",
            " |      \n",
            " |      .. note:: Feature importance is defined only for tree boosters\n",
            " |      \n",
            " |          Feature importance is only defined when the decision tree model is chosen as base\n",
            " |          learner (`booster=gbtree`). It is not defined for other base learner types, such\n",
            " |          as linear learners (`booster=gblinear`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : array of shape ``[n_features]``\n",
            " |  \n",
            " |  intercept_\n",
            " |      Intercept (bias) property\n",
            " |      \n",
            " |      .. note:: Intercept is defined only for linear learners\n",
            " |      \n",
            " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
            " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
            " |          as tree learners (`booster=gbtree`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for X.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of self.predict(X) wrt. y.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzr6X6TAwaZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}