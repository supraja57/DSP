{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class(day-32:30-6-20)\n",
    "- Problem Statement:\n",
    "The problem that we are going to solve here is that given a set of features that describe a tumour whether it is Malignant or Benign, our machine learning model must predict whether the tumour is Malignant or Benign. To train our machine learning model with tumour data, we will be using [SCLCData]\n",
    "### https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv\n",
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  87139402         B        12.32         12.39           78.85      464.1   \n",
       "1   8910251         B        10.60         18.95           69.28      346.4   \n",
       "2    905520         B        11.04         16.83           70.92      373.2   \n",
       "3    868871         B        11.28         13.39           73.00      384.8   \n",
       "4   9012568         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  ...  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700  ...   \n",
       "1          0.09688           0.11470         0.06387      0.02642  ...   \n",
       "2          0.10770           0.07804         0.03046      0.02480  ...   \n",
       "3          0.11640           0.11360         0.04635      0.04796  ...   \n",
       "4          0.07963           0.06934         0.03393      0.02657  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         13.50          15.64            86.97       549.1            0.1385   \n",
       "1         11.88          22.94            78.28       424.8            0.1213   \n",
       "2         12.41          26.44            79.93       471.4            0.1369   \n",
       "3         11.92          15.77            76.53       434.0            0.1367   \n",
       "4         16.20          15.73           104.50       819.1            0.1126   \n",
       "\n",
       "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
       "0             0.1266          0.12420       0.09391          0.2827   \n",
       "1             0.2515          0.19160       0.07926          0.2940   \n",
       "2             0.1482          0.10670       0.07431          0.2998   \n",
       "3             0.1822          0.08669       0.08611          0.2102   \n",
       "4             0.1737          0.13620       0.08178          0.2487   \n",
       "\n",
       "   dimension_worst  \n",
       "0          0.06771  \n",
       "1          0.07587  \n",
       "2          0.07881  \n",
       "3          0.06784  \n",
       "4          0.06766  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for frequency of B and M\n",
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "diagnosis            0\n",
       "radius_mean          0\n",
       "texture_mean         0\n",
       "perimeter_mean       0\n",
       "area_mean            0\n",
       "smoothness_mean      0\n",
       "compactness_mean     0\n",
       "concavity_mean       0\n",
       "points_mean          0\n",
       "symmetry_mean        0\n",
       "dimension_mean       0\n",
       "radius_se            0\n",
       "texture_se           0\n",
       "perimeter_se         0\n",
       "area_se              0\n",
       "smoothness_se        0\n",
       "compactness_se       0\n",
       "concavity_se         0\n",
       "points_se            0\n",
       "symmetry_se          0\n",
       "dimension_se         0\n",
       "radius_worst         0\n",
       "texture_worst        0\n",
       "perimeter_worst      0\n",
       "area_worst           0\n",
       "smoothness_worst     0\n",
       "compactness_worst    0\n",
       "concavity_worst      0\n",
       "points_worst         0\n",
       "symmetry_worst       0\n",
       "dimension_worst      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        12.32         12.39           78.85      464.1          0.10280   \n",
       "1        10.60         18.95           69.28      346.4          0.09688   \n",
       "2        11.04         16.83           70.92      373.2          0.10770   \n",
       "3        11.28         13.39           73.00      384.8          0.11640   \n",
       "4        15.19         13.21           97.65      711.8          0.07963   \n",
       "\n",
       "   compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           0.06981         0.03987      0.03700         0.1959   \n",
       "1           0.11470         0.06387      0.02642         0.1922   \n",
       "2           0.07804         0.03046      0.02480         0.1714   \n",
       "3           0.11360         0.04635      0.04796         0.1771   \n",
       "4           0.06934         0.03393      0.02657         0.1721   \n",
       "\n",
       "   dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.05955  ...         13.50          15.64            86.97   \n",
       "1         0.06491  ...         11.88          22.94            78.28   \n",
       "2         0.06340  ...         12.41          26.44            79.93   \n",
       "3         0.06072  ...         11.92          15.77            76.53   \n",
       "4         0.05544  ...         16.20          15.73           104.50   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       549.1            0.1385             0.1266          0.12420   \n",
       "1       424.8            0.1213             0.2515          0.19160   \n",
       "2       471.4            0.1369             0.1482          0.10670   \n",
       "3       434.0            0.1367             0.1822          0.08669   \n",
       "4       819.1            0.1126             0.1737          0.13620   \n",
       "\n",
       "   points_worst  symmetry_worst  dimension_worst  \n",
       "0       0.09391          0.2827          0.06771  \n",
       "1       0.07926          0.2940          0.07587  \n",
       "2       0.07431          0.2998          0.07881  \n",
       "3       0.08611          0.2102          0.06784  \n",
       "4       0.08178          0.2487          0.06766  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# preparing Input and Output\n",
    "# Drop the id and diagnosis columns\n",
    "x = data.drop(['id','diagnosis'],axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    B\n",
       "1    B\n",
       "2    B\n",
       "3    B\n",
       "4    B\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing Input and Output\n",
    "y = data.diagnosis\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preparing Training and Testing Data\n",
    "# Storing 70% of the data(569 rows) into training and remaining 30% of the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before splitting if you apply standardization --> you are considering whole\n",
    "# you are including test data also into training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0654828 , -1.35518629,  0.03134589, ..., -0.04689041,\n",
       "         0.3683001 , -1.22806684],\n",
       "       [-0.77639967, -0.1225787 , -0.77192193, ..., -0.39868555,\n",
       "         0.3648074 , -0.83648993],\n",
       "       [-0.84936282, -1.05782571, -0.87563499, ..., -1.03880764,\n",
       "        -1.65746674, -0.54459715],\n",
       "       ...,\n",
       "       [-0.88303812, -0.35998755, -0.85204535, ..., -0.1993652 ,\n",
       "        -0.98162901, -0.01313199],\n",
       "       [ 1.07854805,  0.213151  ,  0.91351698, ...,  0.10120204,\n",
       "         3.54665843, -1.20658794],\n",
       "       [-0.26846391, -0.90674734, -0.26149099, ..., -0.22037015,\n",
       "         1.74267813,  0.1823811 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_x_train = scaler.fit_transform(x_train)\n",
    "scaled_x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame out of array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065483</td>\n",
       "      <td>-1.355186</td>\n",
       "      <td>0.031346</td>\n",
       "      <td>-0.035592</td>\n",
       "      <td>0.240960</td>\n",
       "      <td>-0.482979</td>\n",
       "      <td>-0.357708</td>\n",
       "      <td>-0.046272</td>\n",
       "      <td>1.043490</td>\n",
       "      <td>-1.165341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125178</td>\n",
       "      <td>-1.425939</td>\n",
       "      <td>0.117536</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>-0.067496</td>\n",
       "      <td>-0.603330</td>\n",
       "      <td>-0.480560</td>\n",
       "      <td>-0.046890</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>-1.228067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.776400</td>\n",
       "      <td>-0.122579</td>\n",
       "      <td>-0.771922</td>\n",
       "      <td>-0.735368</td>\n",
       "      <td>0.647407</td>\n",
       "      <td>-0.311306</td>\n",
       "      <td>-0.538400</td>\n",
       "      <td>-0.554964</td>\n",
       "      <td>0.487938</td>\n",
       "      <td>-0.040111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.762720</td>\n",
       "      <td>-0.388938</td>\n",
       "      <td>-0.811034</td>\n",
       "      <td>-0.683149</td>\n",
       "      <td>0.750316</td>\n",
       "      <td>-0.570666</td>\n",
       "      <td>-0.484590</td>\n",
       "      <td>-0.398686</td>\n",
       "      <td>0.364807</td>\n",
       "      <td>-0.836490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.849363</td>\n",
       "      <td>-1.057826</td>\n",
       "      <td>-0.875635</td>\n",
       "      <td>-0.787151</td>\n",
       "      <td>0.348139</td>\n",
       "      <td>-0.852027</td>\n",
       "      <td>-0.784787</td>\n",
       "      <td>-0.557750</td>\n",
       "      <td>-0.867159</td>\n",
       "      <td>0.635322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.993986</td>\n",
       "      <td>-1.439473</td>\n",
       "      <td>-1.023193</td>\n",
       "      <td>-0.826151</td>\n",
       "      <td>-0.423640</td>\n",
       "      <td>-1.070632</td>\n",
       "      <td>-1.104405</td>\n",
       "      <td>-1.038808</td>\n",
       "      <td>-1.657467</td>\n",
       "      <td>-0.544597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.495772</td>\n",
       "      <td>1.855828</td>\n",
       "      <td>-0.430686</td>\n",
       "      <td>-0.494085</td>\n",
       "      <td>0.543011</td>\n",
       "      <td>0.675764</td>\n",
       "      <td>0.293648</td>\n",
       "      <td>-0.056654</td>\n",
       "      <td>0.547997</td>\n",
       "      <td>1.030554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106089</td>\n",
       "      <td>2.370196</td>\n",
       "      <td>-0.140978</td>\n",
       "      <td>-0.177502</td>\n",
       "      <td>2.078160</td>\n",
       "      <td>1.517193</td>\n",
       "      <td>0.926643</td>\n",
       "      <td>0.515256</td>\n",
       "      <td>0.635492</td>\n",
       "      <td>2.064263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.540673</td>\n",
       "      <td>-1.208904</td>\n",
       "      <td>-0.589306</td>\n",
       "      <td>-0.538871</td>\n",
       "      <td>-1.270688</td>\n",
       "      <td>-1.348603</td>\n",
       "      <td>-0.942352</td>\n",
       "      <td>-1.083888</td>\n",
       "      <td>-0.465510</td>\n",
       "      <td>-0.868918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.684254</td>\n",
       "      <td>-1.498682</td>\n",
       "      <td>-0.738234</td>\n",
       "      <td>-0.623056</td>\n",
       "      <td>-1.368960</td>\n",
       "      <td>-1.264486</td>\n",
       "      <td>-1.095436</td>\n",
       "      <td>-1.409643</td>\n",
       "      <td>-0.974644</td>\n",
       "      <td>-1.247343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.601481</td>\n",
       "      <td>0.093248</td>\n",
       "      <td>0.734561</td>\n",
       "      <td>0.453131</td>\n",
       "      <td>0.487333</td>\n",
       "      <td>1.735231</td>\n",
       "      <td>1.756211</td>\n",
       "      <td>1.116199</td>\n",
       "      <td>1.328773</td>\n",
       "      <td>0.501121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253200</td>\n",
       "      <td>-0.385555</td>\n",
       "      <td>0.465193</td>\n",
       "      <td>0.119998</td>\n",
       "      <td>0.284251</td>\n",
       "      <td>1.354538</td>\n",
       "      <td>1.668284</td>\n",
       "      <td>0.992779</td>\n",
       "      <td>0.815366</td>\n",
       "      <td>0.459404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1.594903</td>\n",
       "      <td>1.438564</td>\n",
       "      <td>1.572400</td>\n",
       "      <td>1.506153</td>\n",
       "      <td>0.410777</td>\n",
       "      <td>1.138790</td>\n",
       "      <td>2.148854</td>\n",
       "      <td>1.697561</td>\n",
       "      <td>1.520214</td>\n",
       "      <td>-0.184636</td>\n",
       "      <td>...</td>\n",
       "      <td>1.335196</td>\n",
       "      <td>1.395787</td>\n",
       "      <td>1.255592</td>\n",
       "      <td>1.250953</td>\n",
       "      <td>-0.164226</td>\n",
       "      <td>0.953898</td>\n",
       "      <td>1.555425</td>\n",
       "      <td>0.927800</td>\n",
       "      <td>0.792663</td>\n",
       "      <td>0.089857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-0.883038</td>\n",
       "      <td>-0.359988</td>\n",
       "      <td>-0.852045</td>\n",
       "      <td>-0.807025</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>-0.065471</td>\n",
       "      <td>-0.416287</td>\n",
       "      <td>-0.505842</td>\n",
       "      <td>-0.668211</td>\n",
       "      <td>0.250414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.938234</td>\n",
       "      <td>0.199767</td>\n",
       "      <td>-0.891856</td>\n",
       "      <td>-0.806991</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0.053292</td>\n",
       "      <td>-0.233178</td>\n",
       "      <td>-0.199365</td>\n",
       "      <td>-0.981629</td>\n",
       "      <td>-0.013132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1.078548</td>\n",
       "      <td>0.213151</td>\n",
       "      <td>0.913517</td>\n",
       "      <td>0.918342</td>\n",
       "      <td>-0.805780</td>\n",
       "      <td>-0.659950</td>\n",
       "      <td>-0.158337</td>\n",
       "      <td>0.205162</td>\n",
       "      <td>1.246191</td>\n",
       "      <td>-1.789158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911896</td>\n",
       "      <td>0.423069</td>\n",
       "      <td>0.676164</td>\n",
       "      <td>0.679640</td>\n",
       "      <td>-1.056784</td>\n",
       "      <td>-0.818649</td>\n",
       "      <td>-0.169695</td>\n",
       "      <td>0.101202</td>\n",
       "      <td>3.546658</td>\n",
       "      <td>-1.206588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-0.268464</td>\n",
       "      <td>-0.906747</td>\n",
       "      <td>-0.261491</td>\n",
       "      <td>-0.321940</td>\n",
       "      <td>-0.122337</td>\n",
       "      <td>-0.311503</td>\n",
       "      <td>0.095801</td>\n",
       "      <td>-0.329864</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>-0.046010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287798</td>\n",
       "      <td>-0.816934</td>\n",
       "      <td>-0.260726</td>\n",
       "      <td>-0.337052</td>\n",
       "      <td>0.728332</td>\n",
       "      <td>-0.116030</td>\n",
       "      <td>0.213217</td>\n",
       "      <td>-0.220370</td>\n",
       "      <td>1.742678</td>\n",
       "      <td>0.182381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       0.065483     -1.355186        0.031346  -0.035592         0.240960   \n",
       "1      -0.776400     -0.122579       -0.771922  -0.735368         0.647407   \n",
       "2      -0.849363     -1.057826       -0.875635  -0.787151         0.348139   \n",
       "3      -0.495772      1.855828       -0.430686  -0.494085         0.543011   \n",
       "4      -0.540673     -1.208904       -0.589306  -0.538871        -1.270688   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "393     0.601481      0.093248        0.734561   0.453131         0.487333   \n",
       "394     1.594903      1.438564        1.572400   1.506153         0.410777   \n",
       "395    -0.883038     -0.359988       -0.852045  -0.807025         0.088542   \n",
       "396     1.078548      0.213151        0.913517   0.918342        -0.805780   \n",
       "397    -0.268464     -0.906747       -0.261491  -0.321940        -0.122337   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           -0.482979       -0.357708    -0.046272       1.043490   \n",
       "1           -0.311306       -0.538400    -0.554964       0.487938   \n",
       "2           -0.852027       -0.784787    -0.557750      -0.867159   \n",
       "3            0.675764        0.293648    -0.056654       0.547997   \n",
       "4           -1.348603       -0.942352    -1.083888      -0.465510   \n",
       "..                ...             ...          ...            ...   \n",
       "393          1.735231        1.756211     1.116199       1.328773   \n",
       "394          1.138790        2.148854     1.697561       1.520214   \n",
       "395         -0.065471       -0.416287    -0.505842      -0.668211   \n",
       "396         -0.659950       -0.158337     0.205162       1.246191   \n",
       "397         -0.311503        0.095801    -0.329864       0.093796   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         -1.165341  ...      0.125178      -1.425939         0.117536   \n",
       "1         -0.040111  ...     -0.762720      -0.388938        -0.811034   \n",
       "2          0.635322  ...     -0.993986      -1.439473        -1.023193   \n",
       "3          1.030554  ...     -0.106089       2.370196        -0.140978   \n",
       "4         -0.868918  ...     -0.684254      -1.498682        -0.738234   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "393        0.501121  ...      0.253200      -0.385555         0.465193   \n",
       "394       -0.184636  ...      1.335196       1.395787         1.255592   \n",
       "395        0.250414  ...     -0.938234       0.199767        -0.891856   \n",
       "396       -1.789158  ...      0.911896       0.423069         0.676164   \n",
       "397       -0.046010  ...     -0.287798      -0.816934        -0.260726   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      0.004168         -0.067496          -0.603330        -0.480560   \n",
       "1     -0.683149          0.750316          -0.570666        -0.484590   \n",
       "2     -0.826151         -0.423640          -1.070632        -1.104405   \n",
       "3     -0.177502          2.078160           1.517193         0.926643   \n",
       "4     -0.623056         -1.368960          -1.264486        -1.095436   \n",
       "..          ...               ...                ...              ...   \n",
       "393    0.119998          0.284251           1.354538         1.668284   \n",
       "394    1.250953         -0.164226           0.953898         1.555425   \n",
       "395   -0.806991          0.508490           0.053292        -0.233178   \n",
       "396    0.679640         -1.056784          -0.818649        -0.169695   \n",
       "397   -0.337052          0.728332          -0.116030         0.213217   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0       -0.046890        0.368300        -1.228067  \n",
       "1       -0.398686        0.364807        -0.836490  \n",
       "2       -1.038808       -1.657467        -0.544597  \n",
       "3        0.515256        0.635492         2.064263  \n",
       "4       -1.409643       -0.974644        -1.247343  \n",
       "..            ...             ...              ...  \n",
       "393      0.992779        0.815366         0.459404  \n",
       "394      0.927800        0.792663         0.089857  \n",
       "395     -0.199365       -0.981629        -0.013132  \n",
       "396      0.101202        3.546658        -1.206588  \n",
       "397     -0.220370        1.742678         0.182381  \n",
       "\n",
       "[398 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalling for training data\n",
    "scaled_x_train =pd.DataFrame(scaler.fit_transform(x_train),columns = x_train.columns)\n",
    "scaled_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.767981</td>\n",
       "      <td>-0.055433</td>\n",
       "      <td>-0.795918</td>\n",
       "      <td>-0.721932</td>\n",
       "      <td>-0.589333</td>\n",
       "      <td>-0.996232</td>\n",
       "      <td>-0.780212</td>\n",
       "      <td>-0.661564</td>\n",
       "      <td>0.810759</td>\n",
       "      <td>-0.417646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.785433</td>\n",
       "      <td>0.137175</td>\n",
       "      <td>-0.806874</td>\n",
       "      <td>-0.716765</td>\n",
       "      <td>-0.854530</td>\n",
       "      <td>-0.972772</td>\n",
       "      <td>-0.923478</td>\n",
       "      <td>-0.752143</td>\n",
       "      <td>0.726302</td>\n",
       "      <td>-0.720284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.116925</td>\n",
       "      <td>-0.731688</td>\n",
       "      <td>-0.158591</td>\n",
       "      <td>-0.209416</td>\n",
       "      <td>-0.875377</td>\n",
       "      <td>-0.728226</td>\n",
       "      <td>-0.760262</td>\n",
       "      <td>-0.697520</td>\n",
       "      <td>0.281483</td>\n",
       "      <td>-0.839423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273344</td>\n",
       "      <td>-0.865993</td>\n",
       "      <td>-0.216452</td>\n",
       "      <td>-0.348722</td>\n",
       "      <td>-0.911689</td>\n",
       "      <td>-0.222689</td>\n",
       "      <td>-0.624656</td>\n",
       "      <td>-0.633669</td>\n",
       "      <td>0.824098</td>\n",
       "      <td>-0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.100998</td>\n",
       "      <td>-0.544639</td>\n",
       "      <td>1.047734</td>\n",
       "      <td>0.940735</td>\n",
       "      <td>-0.426476</td>\n",
       "      <td>0.438365</td>\n",
       "      <td>0.300001</td>\n",
       "      <td>0.371772</td>\n",
       "      <td>-0.289084</td>\n",
       "      <td>-0.675726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870599</td>\n",
       "      <td>-0.559798</td>\n",
       "      <td>0.797992</td>\n",
       "      <td>0.733636</td>\n",
       "      <td>-0.216988</td>\n",
       "      <td>0.157285</td>\n",
       "      <td>0.858626</td>\n",
       "      <td>0.630104</td>\n",
       "      <td>-0.015897</td>\n",
       "      <td>-0.042321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.922326</td>\n",
       "      <td>1.220340</td>\n",
       "      <td>-0.929322</td>\n",
       "      <td>-0.818221</td>\n",
       "      <td>-0.951934</td>\n",
       "      <td>-0.683493</td>\n",
       "      <td>-0.888348</td>\n",
       "      <td>-1.005166</td>\n",
       "      <td>0.671871</td>\n",
       "      <td>0.132434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647087</td>\n",
       "      <td>1.035458</td>\n",
       "      <td>-0.669891</td>\n",
       "      <td>-0.636120</td>\n",
       "      <td>-0.476402</td>\n",
       "      <td>-0.531335</td>\n",
       "      <td>-0.990740</td>\n",
       "      <td>-1.196269</td>\n",
       "      <td>0.363061</td>\n",
       "      <td>-0.372215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570612</td>\n",
       "      <td>-1.021855</td>\n",
       "      <td>0.510866</td>\n",
       "      <td>0.408905</td>\n",
       "      <td>-0.045084</td>\n",
       "      <td>-0.310914</td>\n",
       "      <td>-0.386171</td>\n",
       "      <td>-0.065263</td>\n",
       "      <td>-0.232778</td>\n",
       "      <td>-0.535625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319276</td>\n",
       "      <td>-0.972569</td>\n",
       "      <td>0.280965</td>\n",
       "      <td>0.134281</td>\n",
       "      <td>-0.467608</td>\n",
       "      <td>-0.472006</td>\n",
       "      <td>-0.138962</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.127664</td>\n",
       "      <td>-0.710370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.860588</td>\n",
       "      <td>-0.549435</td>\n",
       "      <td>-0.846758</td>\n",
       "      <td>-0.785752</td>\n",
       "      <td>0.842278</td>\n",
       "      <td>-0.447664</td>\n",
       "      <td>-0.697999</td>\n",
       "      <td>-0.583830</td>\n",
       "      <td>-0.311607</td>\n",
       "      <td>0.150131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.775109</td>\n",
       "      <td>0.187925</td>\n",
       "      <td>-0.787857</td>\n",
       "      <td>-0.695690</td>\n",
       "      <td>0.249076</td>\n",
       "      <td>-0.631995</td>\n",
       "      <td>-0.765225</td>\n",
       "      <td>-0.566574</td>\n",
       "      <td>0.256534</td>\n",
       "      <td>-0.231776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-0.086056</td>\n",
       "      <td>-0.798834</td>\n",
       "      <td>-0.053251</td>\n",
       "      <td>-0.195421</td>\n",
       "      <td>0.355099</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>-0.095310</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>-0.506801</td>\n",
       "      <td>0.483424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083880</td>\n",
       "      <td>-0.756033</td>\n",
       "      <td>0.114565</td>\n",
       "      <td>-0.101734</td>\n",
       "      <td>0.433744</td>\n",
       "      <td>0.741246</td>\n",
       "      <td>0.097336</td>\n",
       "      <td>0.400409</td>\n",
       "      <td>-0.457724</td>\n",
       "      <td>1.100466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.647311</td>\n",
       "      <td>-0.446318</td>\n",
       "      <td>-0.670242</td>\n",
       "      <td>-0.621444</td>\n",
       "      <td>-0.329040</td>\n",
       "      <td>-0.756086</td>\n",
       "      <td>-0.722523</td>\n",
       "      <td>-0.797030</td>\n",
       "      <td>0.187639</td>\n",
       "      <td>-0.323262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560362</td>\n",
       "      <td>-0.141953</td>\n",
       "      <td>-0.607491</td>\n",
       "      <td>-0.537882</td>\n",
       "      <td>-0.300528</td>\n",
       "      <td>-0.469339</td>\n",
       "      <td>-0.572761</td>\n",
       "      <td>-0.880137</td>\n",
       "      <td>-0.125917</td>\n",
       "      <td>-0.099598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2.144933</td>\n",
       "      <td>0.448162</td>\n",
       "      <td>2.259753</td>\n",
       "      <td>2.343085</td>\n",
       "      <td>-0.110505</td>\n",
       "      <td>1.868645</td>\n",
       "      <td>1.704113</td>\n",
       "      <td>1.543105</td>\n",
       "      <td>-0.285331</td>\n",
       "      <td>-0.065182</td>\n",
       "      <td>...</td>\n",
       "      <td>2.483269</td>\n",
       "      <td>0.482278</td>\n",
       "      <td>2.658104</td>\n",
       "      <td>2.635688</td>\n",
       "      <td>-0.177417</td>\n",
       "      <td>1.529859</td>\n",
       "      <td>1.622939</td>\n",
       "      <td>1.092515</td>\n",
       "      <td>-0.031614</td>\n",
       "      <td>0.306298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-0.577154</td>\n",
       "      <td>0.863028</td>\n",
       "      <td>-0.528298</td>\n",
       "      <td>-0.576939</td>\n",
       "      <td>-1.826769</td>\n",
       "      <td>0.126410</td>\n",
       "      <td>-0.075742</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>-2.229763</td>\n",
       "      <td>0.620575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742071</td>\n",
       "      <td>0.571937</td>\n",
       "      <td>-0.567080</td>\n",
       "      <td>-0.666079</td>\n",
       "      <td>-1.901416</td>\n",
       "      <td>0.522594</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>-0.039335</td>\n",
       "      <td>-1.152771</td>\n",
       "      <td>0.576712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0      -0.767981     -0.055433       -0.795918  -0.721932        -0.589333   \n",
       "1      -0.116925     -0.731688       -0.158591  -0.209416        -0.875377   \n",
       "2       1.100998     -0.544639        1.047734   0.940735        -0.426476   \n",
       "3      -0.922326      1.220340       -0.929322  -0.818221        -0.951934   \n",
       "4       0.570612     -1.021855        0.510866   0.408905        -0.045084   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "166    -0.860588     -0.549435       -0.846758  -0.785752         0.842278   \n",
       "167    -0.086056     -0.798834       -0.053251  -0.195421         0.355099   \n",
       "168    -0.647311     -0.446318       -0.670242  -0.621444        -0.329040   \n",
       "169     2.144933      0.448162        2.259753   2.343085        -0.110505   \n",
       "170    -0.577154      0.863028       -0.528298  -0.576939        -1.826769   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           -0.996232       -0.780212    -0.661564       0.810759   \n",
       "1           -0.728226       -0.760262    -0.697520       0.281483   \n",
       "2            0.438365        0.300001     0.371772      -0.289084   \n",
       "3           -0.683493       -0.888348    -1.005166       0.671871   \n",
       "4           -0.310914       -0.386171    -0.065263      -0.232778   \n",
       "..                ...             ...          ...            ...   \n",
       "166         -0.447664       -0.697999    -0.583830      -0.311607   \n",
       "167          0.532539       -0.095310     0.071722      -0.506801   \n",
       "168         -0.756086       -0.722523    -0.797030       0.187639   \n",
       "169          1.868645        1.704113     1.543105      -0.285331   \n",
       "170          0.126410       -0.075742    -0.457733      -2.229763   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         -0.417646  ...     -0.785433       0.137175        -0.806874   \n",
       "1         -0.839423  ...     -0.273344      -0.865993        -0.216452   \n",
       "2         -0.675726  ...      0.870599      -0.559798         0.797992   \n",
       "3          0.132434  ...     -0.647087       1.035458        -0.669891   \n",
       "4         -0.535625  ...      0.319276      -0.972569         0.280965   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "166        0.150131  ...     -0.775109       0.187925        -0.787857   \n",
       "167        0.483424  ...      0.083880      -0.756033         0.114565   \n",
       "168       -0.323262  ...     -0.560362      -0.141953        -0.607491   \n",
       "169       -0.065182  ...      2.483269       0.482278         2.658104   \n",
       "170        0.620575  ...     -0.742071       0.571937        -0.567080   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0     -0.716765         -0.854530          -0.972772        -0.923478   \n",
       "1     -0.348722         -0.911689          -0.222689        -0.624656   \n",
       "2      0.733636         -0.216988           0.157285         0.858626   \n",
       "3     -0.636120         -0.476402          -0.531335        -0.990740   \n",
       "4      0.134281         -0.467608          -0.472006        -0.138962   \n",
       "..          ...               ...                ...              ...   \n",
       "166   -0.695690          0.249076          -0.631995        -0.765225   \n",
       "167   -0.101734          0.433744           0.741246         0.097336   \n",
       "168   -0.537882         -0.300528          -0.469339        -0.572761   \n",
       "169    2.635688         -0.177417           1.529859         1.622939   \n",
       "170   -0.666079         -1.901416           0.522594         0.164345   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0       -0.752143        0.726302        -0.720284  \n",
       "1       -0.633669        0.824098        -0.330910  \n",
       "2        0.630104       -0.015897        -0.042321  \n",
       "3       -1.196269        0.363061        -0.372215  \n",
       "4        0.016578       -0.127664        -0.710370  \n",
       "..            ...             ...              ...  \n",
       "166     -0.566574        0.256534        -0.231776  \n",
       "167      0.400409       -0.457724         1.100466  \n",
       "168     -0.880137       -0.125917        -0.099598  \n",
       "169      1.092515       -0.031614         0.306298  \n",
       "170     -0.039335       -1.152771         0.576712  \n",
       "\n",
       "[171 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# scalling for testing data\n",
    "scaled_x_test =pd.DataFrame(scaler.transform(x_test),columns = x_test.columns)\n",
    "scaled_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=6, metric='euclidean')\n",
    "\n",
    "# apply the knn object an the dataset\n",
    "# SYNTAX: objectName.fit(Input,Output)\n",
    "knn.fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# predictions on the data\n",
    "# predict function --> gives the predicted values\n",
    "# SYNTAX: objectname.predict(Input)\n",
    "y_train_pred = knn.predict(scaled_x_train)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.98       257\n",
      "           M       1.00      0.94      0.97       141\n",
      "\n",
      "    accuracy                           0.98       398\n",
      "   macro avg       0.98      0.97      0.97       398\n",
      "weighted avg       0.98      0.98      0.98       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy,classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9181286549707602,\n",
       " 0.9473684210526315,\n",
       " 0.9590643274853801,\n",
       " 0.9415204678362573,\n",
       " 0.9590643274853801,\n",
       " 0.9590643274853801,\n",
       " 0.9649122807017544,\n",
       " 0.9532163742690059,\n",
       " 0.9590643274853801,\n",
       " 0.9532163742690059,\n",
       " 0.9532163742690059,\n",
       " 0.9415204678362573,\n",
       " 0.9473684210526315,\n",
       " 0.935672514619883,\n",
       " 0.9473684210526315,\n",
       " 0.9415204678362573,\n",
       " 0.9415204678362573,\n",
       " 0.9415204678362573,\n",
       " 0.9473684210526315]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Checking for optimum k-value\n",
    "# Build the models with multiple k values\n",
    "scores=[]\n",
    "for k in range(1, 20):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(scaled_x_train, y_train)\n",
    "    pred_test = knn_model.predict(scaled_x_test)\n",
    "    scores.append(accuracy_score(y_test, pred_test))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x4c7d0d0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot of k values and scores\n",
    "plt.plot(range(1,20),scores,marker='o',markerfacecolor='r',linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimum k value is 7\n",
    "final_model = KNeighborsClassifier(n_neighbors=7,metric='euclidean')\n",
    "final_model.fit(scaled_x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction on training data\n",
    "final_train_pred = final_model.predict(scaled_x_train)\n",
    "final_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x4cef570>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_train,final_train_pred),annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x9e74e70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_train,final_train_pred),annot=True,fmt='d',annot_kws={'va':'center','ha':'right'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.99       257\n",
      "           M       1.00      0.95      0.97       141\n",
      "\n",
      "    accuracy                           0.98       398\n",
      "   macro avg       0.99      0.98      0.98       398\n",
      "weighted avg       0.98      0.98      0.98       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "# precision --> ppv --> out of the positive predicted values,how many truely positive\n",
    "print(classification_report(y_train,final_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'M',\n",
       "       'M', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_pred = final_model.predict(scaled_x_test)\n",
    "final_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
